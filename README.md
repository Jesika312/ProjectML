# ML-JESIL: Text Classification with SVM

Proyek machine learning untuk klasifikasi teks dalam bahasa Indonesia menggunakan Support Vector Machine (SVM). Proyek ini dirancang untuk menganalisis komentar YouTube dan melakukan prediksi label berdasarkan model yang dilatih.

---

## ğŸ“‹ Daftar Isi
1. [Deskripsi Proyek](#deskripsi-proyek)
2. [Struktur Direktori](#struktur-direktori)
3. [Persyaratan Sistem](#persyaratan-sistem)
4. [Instalasi](#instalasi)
5. [Alur Kerja](#alur-kerja)
6. [Cara Menjalankan](#cara-menjalankan)
7. [File Output](#file-output)
8. [Konfigurasi](#konfigurasi)

---

## ğŸ¯ Deskripsi Proyek

Proyek ini mengimplementasikan pipeline lengkap untuk text classification:

- **Input**: Komentar YouTube dalam bahasa Indonesia (berlabel dan tidak berlabel)
- **Proses**: EDA, preprocessing, balancing dataset, training model SVM
- **Output**: Model terlatih + prediksi untuk dataset baru

Teknologi yang digunakan:
- **Framework**: scikit-learn (SVM, TF-IDF)
- **NLP**: Sastrawi (stemmer Indonesia), Unidecode, Emoji handling
- **Data Processing**: Pandas, NumPy
- **Visualisasi**: Matplotlib, Seaborn, WordCloud

---

## ğŸ“ Struktur Direktori

```
ml-jesil/
â”œâ”€â”€ README.md                                  # Dokumentasi proyek (File ini)
â”œâ”€â”€ eda_preprocessing.py                       # Script EDA & preprocessing
â”œâ”€â”€ balance_dataset.py                         # Script balancing dataset
â”œâ”€â”€ training.py                                # Script training model
â”œâ”€â”€ testing.py                                 # Script testing/prediksi
â”‚
â”œâ”€â”€ dataset/                                   # Folder input data
â”‚   â”œâ”€â”€ data_komentar_dengan_prediksi - 
â”‚   â”‚   data_komentar_dengan_prediksi(2).csv  # Dataset berlabel (Kaggle-like) âœ“
â”‚   â””â”€â”€ youtube_comments_judol.csv            # Dataset scraped (tanpa label) âœ“
â”‚
â”œâ”€â”€ preprocessed_kaggle.csv                    # Data berlabel setelah preprocessing âœ“
â”œâ”€â”€ balanced_dataset_undersample.csv           # Data balanced untuk training âœ“
â”‚
â”œâ”€â”€ training_outputs/                          # Output dari training âœ“
â”‚   â”œâ”€â”€ svm_model_training_only.joblib        # Model SVM terlatih âœ“
â”‚   â”œâ”€â”€ classification_report.json            # Report dalam format JSON âœ“
â”‚   â”œâ”€â”€ classification_report.csv             # Report dalam format CSV âœ“
â”‚   â”œâ”€â”€ summary_metrics.csv                   # Ringkasan metrik performa âœ“
â”‚   â”œâ”€â”€ confusion_matrix.png                  # Confusion matrix heatmap âœ“
â”‚   â”œâ”€â”€ roc_curve.png                         # ROC curve plot âœ“
â”‚   â”œâ”€â”€ pr_curve.png                          # Precision-Recall curve âœ“
â”‚   â”œâ”€â”€ performance_comparison.png            # Grouped bar chart metrics âœ“
â”‚   â”œâ”€â”€ top_positive_features.csv             # Top 20 fitur positif âœ“
â”‚   â””â”€â”€ top_negative_features.csv             # Top 20 fitur negatif âœ“
â”‚
â”œâ”€â”€ outputs_kaggle/                            # Visualisasi EDA (dataset berlabel) âœ“
â”‚   â”œâ”€â”€ label_distribution.png                # Distribusi label chart âœ“
â”‚   â”œâ”€â”€ length_boxplot.png                    # Boxplot panjang teks âœ“
â”‚   â”œâ”€â”€ length_histogram.png                  # Histogram panjang teks âœ“
â”‚   â”œâ”€â”€ wordcloud_overall.png                 # Word cloud keseluruhan âœ“
â”‚   â”œâ”€â”€ wordcloud_promosi.png                 # Word cloud per label âœ“
â”‚   â”œâ”€â”€ top20_overall.csv                     # Top 20 kata keseluruhan âœ“
â”‚   â”œâ”€â”€ top20_overall.png                     # Bar chart top 20 kata âœ“
â”‚   â”œâ”€â”€ top20_promosi.csv                     # Top 20 kata per label âœ“
â”‚   â””â”€â”€ top20_promosi.png                     # Bar chart top 20 kata per label âœ“
â”‚
â””â”€â”€ test_outputs/                              # Output dari testing âœ“
      â””â”€â”€ predicted_scraped_dataset.csv         # Data + prediksi + score âœ“
```

---

## ğŸ”§ Persyaratan Sistem

- **Python**: 3.8 atau lebih baru
- **OS**: Windows, macOS, atau Linux
- **RAM**: Minimal 4GB
- **Disk Space**: 500MB (untuk dataset dan model)

---

## ğŸ“¦ Instalasi

### 1. Clone atau Download Proyek

```bash
cd e:\ml-jesil
```

### 2. Install Dependencies

Jalankan perintah berikut untuk install semua package yang diperlukan:

```bash
pip install pandas numpy scikit-learn joblib matplotlib seaborn wordcloud unidecode emoji sastrawi
```

**Penjelasan package:**
- `pandas`, `numpy`: Data manipulation
- `scikit-learn`: ML algorithms (SVM, TF-IDF, metrics)
- `joblib`: Model serialization
- `matplotlib`, `seaborn`: Plotting
- `wordcloud`: Visualisasi word frequency
- `unidecode`: Unicode normalization
- `emoji`: Emoji processing
- `sastrawi`: Stemmer untuk Bahasa Indonesia

### 3. Verifikasi Instalasi

```bash
python -c "import pandas, sklearn, joblib; print('âœ“ Dependencies OK')"
```

---

## ğŸ”„ Alur Kerja

### Fase 1: Exploratory Data Analysis (EDA) & Preprocessing
**Script**: `eda_preprocessing.py`

```
Dataset Raw (CSV)
        â†“
    [EDA]
    - Analisis distribusi label
    - Visualisasi word frequency
    - Deteksi missing values
        â†“
  [Preprocessing]
  - Lowercase
  - Remove URLs, mentions, hashtags
  - Remove special characters
  - Stemming (Sastrawi)
  - Remove emoji
        â†“
Preprocessed CSV (siap training)
```

**Input**: 
- Dataset berlabel: `dataset/data_komentar_dengan_prediksi - data_komentar_dengan_prediksi(2).csv`
- Dataset scraped (optional): `dataset/youtube_comments_judol.csv`

**Output**:
- `preprocessed_kaggle.csv` (data berlabel setelah preprocessing)
- `outputs_kaggle/` (visualisasi EDA)

---

### Fase 2: Dataset Balancing
**Script**: `balance_dataset.py`

```
Preprocessed Data (mungkin imbalanced)
        â†“
  [Undersample]
  - Identifikasi majority & minority class
  - Undersample majority class ke jumlah minority
  - Ratio akhir: 50:50
        â†“
Balanced Dataset (siap training)
```

**Input**: `preprocessed_kaggle.csv`

**Output**: `balanced_dataset_undersample.csv`

---

### Fase 3: Model Training
**Script**: `training.py`

```
Balanced Dataset
        â†“
  [Train-Test Split]
  - Train: 80%
  - Test: 20%
        â†“
  [Pipeline]
  â”œâ”€ TF-IDF Vectorizer
  â””â”€ Linear SVC
        â†“
  [Training]
  - Fit model pada training data
        â†“
  [Evaluation]
  - Prediksi pada test data
  - Hitung: Accuracy, Precision, Recall, F1
  - Generate: Confusion Matrix, ROC Curve
  - Extract: Top features
        â†“
Model + Reports (dalam training_outputs/)
```

**Input**: `balanced_dataset_undersample.csv`

**Outputs**:
- `svm_model_training_only.joblib` (model terlatih)
- Classification report (JSON & CSV)
- Performance plots (PNG)
- Top features (CSV)

---

### Fase 4: Testing & Prediksi
**Script**: `testing.py`

```
Model + Dataset Baru (tanpa label)
        â†“
  [Detect Text Column]
  - Otomatis cari kolom teks ("komentar", "comment", dll)
        â†“
  [Preprocessing]
  - Sama seperti fase 1
        â†“
  [Predict]
  - Gunakan model untuk prediksi
  - Hitung prediction score
        â†“
CSV dengan Prediksi
```

**Input**: `dataset/youtube_comments_judol.csv` (atau file lainnya)

**Output**: `test_outputs/predicted_scraped_dataset.csv`

---

## ğŸš€ Cara Menjalankan

### Opsi 1: Jalankan Semua Script Secara Berurutan

#### Langkah 1: EDA & Preprocessing
```bash
python eda_preprocessing.py
```
âœ… Output: `preprocessed_kaggle.csv`, `outputs_kaggle/`

#### Langkah 2: Balancing Dataset
```bash
python balance_dataset.py
```
âœ… Output: `balanced_dataset_undersample.csv`

#### Langkah 3: Training Model
```bash
python training.py
```
âœ… Output: Model + reports dalam `training_outputs/`

#### Langkah 4: Testing & Prediksi
```bash
python testing.py
```
âœ… Output: `test_outputs/predicted_scraped_dataset.csv`

---

### Opsi 2: Jalankan Hanya Testing (Jika Model Sudah Ada)

Jika model `svm_model_training_only.joblib` sudah tersedia di `training_outputs/`:

```bash
python testing.py
```

Script ini akan:
- Otomatis load model
- Detect kolom teks di file scraped
- Melakukan preprocessing
- Generate prediksi
- Simpan hasil ke `test_outputs/`

---

## ğŸ“Š File Output

### Dari Training

| File | Deskripsi |
|------|-----------|

### Dari Testing

| File | Deskripsi |
|------|-----------|
| `predicted_scraped_dataset.csv` | Data scraped + kolom `predicted_label` + `predicted_score` |
| File | Deskripsi |
|------|-----------|
| `confusion_matrix.png` | Heatmap confusion matrix âœ“ |
| `roc_curve.png` | ROC curve plot âœ“ |
| `pr_curve.png` | Precision-Recall curve âœ“ |
| `performance_comparison.png` | Bar chart perbandingan metrik âœ“ |
| `classification_report.json` | Metrics dalam format JSON âœ“ |
| `classification_report.csv` | Metrics dalam format CSV âœ“ |
| `summary_metrics.csv` | Ringkasan: Accuracy, Precision, Recall, F1 âœ“ |
| `top_positive_features.csv` | Top 20 fitur dengan koefisien positif terbesar âœ“ |
| `top_negative_features.csv` | Top 20 fitur dengan koefisien negatif terbesar âœ“ |
| `svm_model_training_only.joblib` | Model SVM terlatih (binary format) âœ“ |
| `predicted_scraped_dataset.csv` | Data scraped + kolom `predicted_label` + `predicted_score` âœ“ |

---

## âš™ï¸ Konfigurasi

Setiap script memiliki section `CONFIG` di awal file untuk kustomisasi:

### `eda_preprocessing.py`
```python
KAGGLE_FILE   = "dataset/data_komentar_dengan_prediksi - data_komentar_dengan_prediksi(2).csv"
SCRAPED_FILE  = None  # Set ke path file jika ingin preprocess dataset scraped
TEXT_COL      = "komentar"   # Nama kolom teks
LABEL_COL     = "label"      # Nama kolom label
OUT_KAGGLE    = "preprocessed_kaggle.csv"
OUT_SCRAPED   = "preprocessed_scraped.csv"
OUTDIR_KAGGLE = "outputs_kaggle"
OUTDIR_SCRAPED= "outputs_scraped"
```

### `balance_dataset.py`
```python
INPUT_FILE = "preprocessed_kaggle.csv"
OUTPUT_FILE = "balanced_dataset_undersample.csv"
LABEL_COL = "label"
RANDOM_STATE = 42
```

### `training.py`
```python
TRAIN_FILE = "balanced_dataset_undersample.csv"
LABEL_COL = "label"
OUT_DIR = "training_outputs"
RANDOM_STATE = 42
```

### `testing.py`
```python
MODEL_PATH = "training_outputs/svm_model_training_only.joblib"
SCRAPED_FILE = "dataset/youtube_comments_judol.csv"
TEXT_COLUMN = None  # Set ke nama kolom jika ingin memaksa (misal "komentar")
OUTPUT_DIR = "test_outputs"
```

---

## ğŸ” Troubleshooting

### Masalah: `ModuleNotFoundError: No module named 'sklearn'`
**Solusi**: Install scikit-learn
```bash
pip install scikit-learn
```

### Masalah: `FileNotFoundError: [Errno 2] No such file or directory`
**Solusi**: Pastikan file input ada di lokasi yang benar. Cek konfigurasi di awal script.

### Masalah: Kolom teks tidak terdeteksi di `testing.py`
**Solusi**: Set `TEXT_COLUMN` secara manual dengan nama kolom yang tepat di config.

### Masalah: Model tidak ditemukan saat testing
**Solusi**: Jalankan `training.py` terlebih dahulu untuk generate model.

### Masalah: Dataset imbalanced di fase 3
**Solusi**: Pastikan sudah menjalankan `balance_dataset.py` di fase 2.

---

## ğŸ“ˆ Metrics Performa

Model akan menghasilkan metrik berikut:

- **Accuracy**: Persentase prediksi benar dari total prediksi
- **Precision**: Dari prediksi positif, berapa yang benar-benar positif
- **Recall**: Dari positif asli, berapa yang terdeteksi oleh model
- **F1-Score**: Harmonic mean dari Precision dan Recall
- **ROC-AUC**: Area Under Curve dari ROC curve
- **PR-AUC**: Area Under Curve dari Precision-Recall curve

---

## ğŸ› ï¸ Tips & Best Practices

1. **Selalu preview data baru**: Pastikan format CSV sesuai sebelum testing
2. **Jaga konsistensi nama kolom**: Gunakan nama yang konsisten di semua script
3. **Check log output**: Setiap script menampilkan progress dan error messages
4. **Backup model**: Simpan model penting sebelum melakukan training ulang
5. **Monitor file size**: Dataset besar dapat memperlambat processing

---

## ğŸ“ Support

Jika ada pertanyaan atau issue, periksa:
- Console output messages
- File `classification_report.json` untuk detail metrics
- Pastikan semua dependencies terinstall dengan benar

---

## ğŸ“ Lisensi

Proyek ini dibuat untuk keperluan pembelajaran dan analisis teks dalam Bahasa Indonesia.

---

**Last Updated**: Desember 2025
